
setup en c9

1 new workspace
2 clone from git
3 https://github.com/ombzzz/mkt.git
4 template: blank
5 create workspace

6

sudo vi /etc/nginx/sites-enabled/default   

server {
	listen 8080 default_server;
	listen [::]:8080 default_server ipv6only=on;

	#root /usr/share/nginx/html;
	root /home/ubuntu/workspace;
	index index.html index.htm;

	# Make site accessible from http://localhost/
	server_name localhost;

	location / {
	# First attempt to serve request as file, then
	# as directory, then fall back to displaying a 404.
	try_files $uri $uri/ =404;
	# Uncomment to enable naxsi on this location
	# include /etc/nginx/naxsi.rules
	}

	location ~ \.php$ {
	fastcgi_split_path_info ^(.+\.php)(/.+)$;
	#       # NOTE: You should have "cgi.fix_pathinfo = 0;" in php.ini
	#
	#       # With php5-cgi alone:
	#       fastcgi_pass 127.0.0.1:9000;
	#       # With php5-fpm:
	fastcgi_pass unix:/var/run/php5-fpm.sock;
	fastcgi_index index.php;
	include fastcgi_params;
}    

7 sudo apt-get install php5-curl

8 http://mkt-obiazzi.c9users.io:8080/index.php

***

echo "# mkt" >> README.md
git init
git add README.md
git config --global user.email "obiazzi@gmail.com"
git config --global user.name "obiazzi"
git commit -m "cs inicial"
git remote add origin https://github.com/ombzzz/mkt.git
git push -u origin master
.
echo sqlite-doc-3220000/ > .gitignore

#luego de trabajar un poco y crear nuevos archivos

git add .

git commit -m avance

git push -u origin master


git config credential.helper store
git config --global credential.helper 'cache --timeout 36000'
#After enabling credential caching, it will be cached for 7200 seconds (2 hour) * 5.


echo mkt.db >> .gitignore
git rm --cached mkt.db


sudo apt-get install php5-cli

sudo apt-get install php5-fpm php5-curl	php5-json;

# en estos se puede cambiar la configuracion del cgi, por ej, el usuario con que corre
# por ahora le dejo el usuario que viene por defecto: www-data
# (www es el pool por defecto)
#/etc/php5/fpm/php-fpm.conf
#/etc/php5/fpm/pool.d/www.conf

#editar /etc/php5/fpm/pool.d/www.conf agregar lo siguiente para que los errores php se muestren en pantalla
#sino van solo a /var/log/nginx/error.log:
php_flag[display_errors] = on
php_flag[display_startup_errors] = on

sudo service php5-fpm restart


sudo apt-get install nginx

#editar /etc/nginx/sites-enabled/default 

server {
	#listen   80; ## listen for ipv4; this line is default and implied
	#listen   [::]:80 default_server ipv6only=on; ## listen for ipv6

	#root /usr/share/nginx/www;
	root /home/eliveuser/mkt;
	index index.html;

	# Make site accessible from http://localhost/
	server_name localhost;

	location / {
		# First attempt to serve request as file, then
		# as directory, then fall back to displaying a 404.
		#try_files $uri $uri/ /index.html;
		try_files $uri $uri/; 

		# Uncomment to enable naxsi on this location
		# include /etc/nginx/naxsi.rules
	}

	location /doc/ {
		alias /usr/share/doc/;
		autoindex on;
		allow 127.0.0.1;
		allow ::1;
		deny all;
	}

    location  ~  \.php  {
      fastcgi_split_path_info ^(.+?\.php)(/.*)$;
      fastcgi_pass unix:/var/run/php5-fpm.sock;
      fastcgi_index index.php;
      # include the fastcgi_param setting
      include fastcgi_params;
      fastcgi_param  SCRIPT_FILENAME   $document_root$fastcgi_script_name;
    }
}

sudo service nginx restart

sudo apt-get install sqlite php5-sqlite

sqlite3 mkt.db

sudo chown www-data mkt.db
sudo chgrp eliveuser mkt.db
sudo chmod 664 mkt.db


***

create table asset (
	tck,
	den,
	sect,
	mkt,
	mervl, 
	balurl, 
	hrurl,
	tipo,
	opctck
	primary key( tck )
);


create table as_pr(
	tck,
	fec,
	open,
	close,
	min,
	max,
	vol,
	montop,
	per,
	yld,
	obs,
	cantop, 
	bid,
	bidq,
	ask,
	askq 
	primary key( tck, fec )
);

***

create table bal( tck, anio, hasta, cuenta, val );

create table balcue( cuenta, descr, unidad, obs );


***

--merval

create table aux_merval(
 fecha,
 apertura,
 maximo,
 minimo,
 cierre,
 volumen,
 openint,
 primary key( fecha )
);

.separator ,
.import merval.csv aux_merval


insert into as_pr values( 'agro', '2018-02-02', 1, 2, 3, 4, 5, 6, 7, 8 );

El método de autenticación que se utiliza en esta plataforma son tokens digitales. Los tokens son simples strings que se envían al servidor. Existen dos tipos de tokens: bearer token y refresh tokens. El bearer token se debe presentar en cada request para poder acceder al recurso solicitado. Este token es válido por 15 minutos desde que se lo solicita. Para renovar este token, se utiliza el refresh token. Para obtener el primer par de tokens se realiza un request POST especificando el nombre de usuario y contraseña a:

https://api.invertironline.com/token 
POST /token HTTP/1.1
Host: api.invertironline.com
Content-Type: application/x-www-form-urlencoded
username=MIUSUARIO&password=MICONTRASEÑA&grant_type=password

Una vez realizada esta petición, se debe utilizar el bearer token para acceder al recurso deseado, para hacer esto, se envía el token en el header de la petición con el Key “authorization” y como valor el token precedido de la palabra Bearer y un espacio como se ve en el ejemplo:


GET /api/micuenta/miportafolio HTTP/1.1
Host: api.invertironline.com
Authorization: Bearer aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa

Una vez expirado el bearer token, se procede a refrescar el mismo con el refresh token. Para realizar esto se debe mandar la siguiente petición al mismo endpoint donde realizamos el login (https://api.invertironline.com/token)

POST /token HTTP/1.1
Host: api.invertironline.com
Content-Type: application/x-www-form-urlencoded
refresh_token=bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb&grant_type=refresh_token

***

siguientes no lo tiene historico iol, lo obtenemos de rava y lo importamos en sqlite 

for x in bma brio capx ceco2 ctio loma rich std tef petr pgr; do
wget -c -O $x.csv http://www.ravaonline.com/v2/empresas/precioshistoricos.php?e=$x&csv=1
done

for x in bma brio capx ceco2 ctio loma rich std tef petr pgr; do
rm $x.0.csv
awk -vt=$x ' NR >= 2 { print t "," $0}' $x.csv >> $x.0.csv
done

create temporary table tmp_rava( tck, fecha, apertura, maximo, minimo, cierre, volumen, openint );

.separator ","
.import bma.0.csv tmp_rava
.import brio.0.csv tmp_rava
.import capx.0.csv tmp_rava
.import ceco2.0.csv tmp_rava
.import ctio.0.csv tmp_rava
.import loma.0.csv tmp_rava
.import rich.0.csv tmp_rava
.import std.0.csv tmp_rava
.import tef.0.csv tmp_rava
.import petr.0.csv tmp_rava
.import pgr.0.csv tmp_rava


delete from as_pr where tck in ( 
'bma', 'brio', 'capx', 'ceco2', 'ctio', 'loma', 'rich', 'std', 'tef', 'petr', 'pgr'
)

select count(*) cant, r.tck, r.fecha
from tmp_rava r
group by r.tck, r.fecha
having count(*) > 1

insert into as_pr( tck, fec, open, max, min, close, vol )
select r.tck, r.fecha, r.apertura, r.maximo, r.minimo, r.cierre, r.volumen from tmp_rava r;

#dezipear balances

for i in *.zip; do
unzip -q -o -d `basename $i .zip` $i
if [ $? -eq 0 ]; then
  echo OK $i
  rm $i
else
  echo FAIL $i
fi
done


for i in *.doc; do
ripole -i $i -d ole --save-unknown-streams 
  for j in ole/*; do
    tipo=`file $j`
    if [ $tipo =~ PDF ]; then
      echo PDF $j
    else 
    	rm $j
    fi
  done 
done


#aluminium lme

https://www.quandl.com/data/LME/PR_AL-Aluminum-Prices

create temporary table tmp_quandl( date, cb, css, b3m, s3m, b15m, s15m, bd1, sd1, bd2, sd2, bd3, sd3 );

tail -n+2 LME-PR_AL.csv > LME-PR_AL_.csv

.separator ","
.import LME-PR_AL_.csv tmp_quandl

insert into asset( tck, den, sect, mkt ) values ( 'alu', 'aluminium lme', 'comm', 'lme' );

insert into as_pr( tck, fec, open, max, min, close, vol )
select 'alu', q.date, q.cb, q.cb, q.cb, q.cb, 0 from tmp_quandl q;


#wti crude oil continuation 1 (nymex CLc1)

https://www.quandl.com/data/CHRIS/CME_CL1
https://www.quandl.com/api/v3/datasets/CHRIS/CME_CL1.csv?api_key=syLZGUe6mpvGgS6XMKjx&start_date=1918-04-01

tail -n+2 CHRIS-CME_CL1.csv > CHRIS-CME_CL1_.csv

create temporary table tmp_quandl( date,open,high,low,last,change,settle,volume,pdoi);

.separator ","
.import CHRIS-CME_CL1_.csv tmp_quandl

insert into asset( tck, den, sect, mkt ) values ( 'wti', 'wti crude oil (nymex CLc1)', 'comm', 'nymex' );

insert into as_pr( tck, fec, open, max, min, close, vol )
select 'wti', q.date, q.open, q.high, q.low, q.settle, volume from tmp_quandl q;

#soybean continuation 1 (cbot Sc1)

https://www.quandl.com/data/CHRIS/CME_S1
https://www.quandl.com/api/v3/datasets/CHRIS/CME_S1.csv?api_key=syLZGUe6mpvGgS6XMKjx

tail -n+2 CHRIS-CME_S1.csv > CHRIS-CME_S1_.csv

create temporary table tmp_quandl( date,open,high,low,last,change,settle,volume,pdoi);

.separator ","
.import CHRIS-CME_S1_.csv tmp_quandl

insert into asset( tck, den, sect, mkt ) values ( 'soyb', 'soybean (cbot Sc1)', 'comm', 'cbot' );

insert into as_pr( tck, fec, open, max, min, close, vol )
select 'soyb', q.date, q.open, q.high, q.low, q.settle, volume from tmp_quandl q;

#merval

for x in merval; do
wget -c -O $x.csv http://www.ravaonline.com/v2/empresas/precioshistoricos.php?e=$x&csv=1
done

for x in merval; do
rm $x.0.csv
awk -vt=$x ' NR >= 2 { print t "," $0}' $x.csv >> $x.0.csv
done

insert into asset( tck, den, sect, mkt ) values ( 'merval', 'merval', 'idx', 'bcba' );

create temporary table tmp_rava( tck, fecha, apertura, maximo, minimo, cierre, volumen, openint );

.separator ","
.import merval.0.csv tmp_rava


delete from as_pr where tck in ( 
'merval'
)

insert into as_pr( tck, fec, open, max, min, close, vol )
select r.tck, r.fecha, r.apertura, r.maximo, r.minimo, r.cierre, r.volumen from tmp_rava r;


***

dolar

wget -c -O dolar.csv "https://docs.google.com/spreadsheets/d/1pixRym_MficABseercu26r9eYa69zHOFQj7g_HtWmT4/gviz/tq?tqx=out:csv&sheet=dolar"

rm dolar.0.csv
awk -vt=$x ' /Fecha/,/FINN/ { print }' dolar.csv  | grep -v FINN | grep -v Fecha >> dolar.0.csv

wget -c -O dolarccl.csv "https://docs.google.com/spreadsheets/d/1pixRym_MficABseercu26r9eYa69zHOFQj7g_HtWmT4/gviz/tq?tqx=out:csv&sheet=dolarccl"

rm dolarccl.0.csv
awk ' NR >= 2 { print }' dolarccl.csv >> dolarccl.0.csv
echa/,/FINN/ { print }' dolar.csv  | grep -v FINN | grep -v Fecha >> dolar.0.csv


create temporary table tmp_dolar( fecha, compra, venta, dia, mes, anio, aniomes, vend , aniomesdia, nul1, nul2 );
.separator ","
.import dolar.0.csv tmp_dolar

insert into as_pr( tck, fec, open, close )
select 
 'usdars' tck, 
 substr( aniomesdia, 1, 4 ) || '-' || substr( aniomesdia, 5, 2 ) || '-' || substr( aniomesdia, 7, 2 ) fec,
 max( vend ) open, max( vend ) close
from tmp_dolar
where aniomesdia > "20180314"
group by aniomesdia
order by aniomesdia desc;

insert into asset( tck, den, tipo )v
alues ( 'usdars', 'usdars', 'fx' )

--contado con liqui
update as_pr
set obs = close
where tck = 'usdars'
and fec between '2011-01-03' and '2015-12-17';

--contado con liqui
update as_pr
set open = null, close = null
where tck = 'usdars'
and fec between '2011-01-03' and '2015-12-17'
and obs is not null;

create temporary table tmp_dolarccl( valor,  fecha, nul );
.separator ","
.import dolarccl.0.csv tmp_dolarccl

update tmp_dolarccl
set fecha = substr( fecha, 1, 4 ) || '-' || substr( fecha, 5, 2 ) || '-' || substr( fecha, 7, 2 ) 


update as_pr
set close = (
select c.valor
from tmp_dolarccl c
where c.fecha = (
 select max( c2.fecha )
 from tmp_dolarccl c2
 where c2.fecha <= fec
) 
)
where 
tck = 'usdars'
and fec between '2011-01-03' and '2015-12-17'
and close is null
and obs is not null;


update as_pr
set open = close
where 
tck = 'usdars'
and fec between '2011-01-03' and '2015-12-17'
and open is null;

***

usdbrl

#requiere login
https://www.investing.com/instruments/DownloadHistoricalData?curr_id=2103&smlID=107254&header=USD%2FBRL+Historical+Data&st_date=01%2F01%2F1992&end_date=12%2F31%2F2011&interval_sec=Daily&sort_col=date&sort_ord=DESC
https://www.investing.com/instruments/DownloadHistoricalData?curr_id=2103&smlID=107254&header=USD%2FBRL+Historical+Data&st_date=01%2F01%2F2012&end_date=03%2F31%2F2018&interval_sec=Daily&sort_col=date&sort_ord=DESC

cat usdbrl2.csv >> usdbrl1.csv
grep -v Change usdbrl1.csv | grep -v Highest > usdbrl.csv

create temporary table tmp_usdbrl( date, price, open, high, low, change );

.separator ","
.import usdbrl.csv tmp_usdbrl

insert into as_pr( tck, fec, open, close, min, max )
select 'usdbrl' tck,
	substr( date, 9, 4 )  
	|| '-'
	|| case substr( date, 1, 3 ) 
	when 'Jan' then '01'
	when 'Feb' then '02'
	when 'Mar' then '03'
	when 'Apr' then '04'
	when 'May' then '05'
	when 'Jun' then '06'
	when 'Jul' then '07'
	when 'Aug' then '08'
	when 'Sep' then '09'
	when 'Oct' then '10'
	when 'Nov' then '11'
	when 'Dec' then '12'
	else '00' end
	|| '-' || substr( date, 5, 2 ) date,
open,
price,
low,
high
from tmp_usdbrl

insert into asset( tck, den, tipo )
values ( 'usdbrl', 'usdbrl', 'fx' )


#pbr

https://www.investing.com/equities/petroleo-bras-historical-data
https://www.investing.com/instruments/DownloadHistoricalData?curr_id=8028&smlID=1160986&header=PBR+Historical+Data&st_date=03%2F09%2F1986&end_date=04%2F09%2F2018&interval_sec=Daily&sort_col=date&sort_ord=DESC

mv ../Downloads/PBR\ Historical\ Data.csv pbr.csv

tail -n+2 pbr.csv | head -n-2 > pbr_.csv


create temporary table tmp_invest( date, price, open, high, low, vol, change );

.separator ","
.import pbr_.csv tmp_invest

insert into as_pr( tck, fec, open, close, min, max, vol )
select 'pbr' tck,
	substr( date, 9, 4 )  
	|| '-'
	|| case substr( date, 1, 3 ) 
	when 'Jan' then '01'
	when 'Feb' then '02'
	when 'Mar' then '03'
	when 'Apr' then '04'
	when 'May' then '05'
	when 'Jun' then '06'
	when 'Jul' then '07'
	when 'Aug' then '08'
	when 'Sep' then '09'
	when 'Oct' then '10'
	when 'Nov' then '11'
	when 'Dec' then '12'
	else '00' end
	|| '-' || substr( date, 5, 2 ) date,
open,
price,
low,
high,
vol
from tmp_invest

insert into asset( tck, den, sect, tipo, mkt ) values ( 'pbr', 'petrobras', 'petroleo', 'acc', 'nyse' );

update as_pr

update as_pr
set vol = substr( vol, 1, length(vol)-1 ) * 1000 
where tck = 'pbr'
and vol like '%K%'

update as_pr
set vol = substr( vol, 1, length(vol)-1 ) * 1000000 
where tck = 'pbr'
and vol like '%M%'
